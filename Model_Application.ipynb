{"cells":[{"cell_type":"code","execution_count":null,"metadata":{"id":"qOQ36lqrz2VV"},"outputs":[],"source":["pip install yfinance"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":5577,"status":"ok","timestamp":1635763035593,"user":{"displayName":"Po-Chen (劉柏辰) Liu","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"11641391203079784915"},"user_tz":-480},"id":"8SSksI63yyHb","outputId":"8135d85e-be82-4dbf-b492-41d89b7ba9c7"},"outputs":[],"source":["# -*- coding: utf-8 -*-\n","\n","'''\n","#################### CONNECT TO THE FOLDER ####################\n","'''\n","def connect_to_the_folder(method):\n","    import os\n","    if method == 'google':\n","        from google.colab import drive\n","        drive.mount('/content/drive/', force_remount=True)\n","        os.chdir('/content/drive/My Drive/Data_Technology/DT_Learning/III_Big_Data/BDSE21_Team1/Final_Project/')\n","    elif method == 'local':\n","        os.chdir('c:\\Shared\\BDSE_Team1\\Final_Project\\\\')\n","\n","connect_to_the_folder('google') # connect to google or local\n","\n","import yfinance as yf\n","from datetime import date, timedelta\n","today = date.today()\n","start = today - timedelta(days=20)\n","today = today.strftime('%Y-%m-%d')\n","start = start.strftime('%Y-%m-%d')\n","\n","import numpy as np\n","import pandas as pd\n","\n","from sklearn.preprocessing import MinMaxScaler\n","from keras.models import load_model\n","model_1 = load_model('Model/Model_Save/rnn_close_1_1.h5')\n","model_2 = load_model('Model/Model_Save/rnn_close_2_1.h5')\n","model_3 = load_model('Model/Model_Save/rnn_close_3_1.h5')\n","model_4 = load_model('Model/Model_Save/rnn_close_4_1.h5')\n","model_5 = load_model('Model/Model_Save/rnn_close_5_1.h5')\n","models = [model_1, model_2, model_3, model_4, model_5]\n","\n","def get_data(code):\n","    # get realtime data\n","    df = yf.Ticker(str(code)+'.TW').history(start=start, end=today)\n","    if len(df) == 0:\n","        df = yf.Ticker(str(code)+'.TWO').history(start=start, end=today)\n","        if len(df) == 0:\n","            pass\n","    \n","    # feature\n","    for day in [1,2,3,4,5,6]:\n","        df[f'{day}days_before_close'] = df['Close'].shift(periods=day+1)\n","    \n","    df = df.iloc[10:]\n","    df_model = df[['Open', 'High', 'Low', 'Close', f'1days_before_close', f'2days_before_close', f'3days_before_close', f'4days_before_close', f'5days_before_close', f'6days_before_close']]\n","    data_all = pd.DataFrame(df_model.values.flatten())\n","    data_all = np.array(data_all).astype(float)\n","    scaler = MinMaxScaler()\n","    data_all = scaler.fit_transform(data_all)\n","    data = []\n","    sequence_length = len(df_model.columns) # Feature Number\n","    for i in range(int(len(data_all) / sequence_length)):\n","        data.append(data_all[i*sequence_length:(i+1)*sequence_length])\n","    test_x = np.array(data).astype('float64')\n","    test_x_last = np.array([test_x[-1]])\n","    predict = models[0].predict(test_x)\n","    predict = np.reshape(predict, (predict.size, ))\n","    predict = scaler.inverse_transform([[i] for i in predict])\n","    area_data2 = predict\n","    labels = df.index.astype(str).str[:10].tolist()\n","    area_data1 = df['Close'].values.tolist()\n","    for day in [1,2,3,4,5]:\n","        labels.append(f'{day} Days Predict')\n","    for day in [1,2,3,4]:\n","        predict = models[day].predict(test_x_last)\n","        predict = np.reshape(predict, (predict.size, ))\n","        predict = scaler.inverse_transform([[i] for i in predict])\n","        area_data2 = np.append(area_data2, predict)\n","    \n","    area_data2 = np.around(area_data2.flatten(), 1).tolist()\n","    labels.pop(0)\n","    area_data1.pop(0)\n","    bar_data = df['Volume'].values.tolist()\n","    labels = str(labels).replace(\"'\", \"\").replace(\"[\", \"\").replace(\"]\", \"\")\n","    area_data1 = str(area_data1).replace(\"[\", \"\").replace(\"]\", \"\")\n","    area_data2 = str(area_data2).replace(\"[\", \"\").replace(\"]\", \"\")\n","    bar_data = str(bar_data).replace(\"[\", \"\").replace(\"]\", \"\")\n","    return labels, area_data1, area_data2, bar_data\n","\n","get_data('2330')\n","\n","def get_twii_data():\n","    df = yf.Ticker('^TWII').history(start=start, end=today)\n","    for day in [1,2,3,4,5,6]:\n","        df[f'{day}days_before_close'] = df['Close'].shift(periods=day+1)\n","    \n","    df = df.iloc[10:]\n","    df_model = df[['Open', 'High', 'Low', 'Close', f'1days_before_close', f'2days_before_close', f'3days_before_close', f'4days_before_close', f'5days_before_close', f'6days_before_close']]\n","    data_all = pd.DataFrame(df_model.values.flatten())\n","    data_all = np.array(data_all).astype(float)\n","    scaler = MinMaxScaler()\n","    data_all = scaler.fit_transform(data_all)\n","    data = []\n","    sequence_length = len(df_model.columns) # Feature Number\n","    for i in range(int(len(data_all) / sequence_length)):\n","        data.append(data_all[i*sequence_length:(i+1)*sequence_length])\n","    test_x = np.array(data).astype('float64')\n","    test_x_last = np.array([test_x[-1]])\n","    predict = models[0].predict(test_x)\n","    predict = np.reshape(predict, (predict.size, ))\n","    predict = scaler.inverse_transform([[i] for i in predict])\n","    area_data2 = predict\n","    labels = df.index.astype(str).str[:10].tolist()\n","    area_data1 = df['Close'].values.tolist()\n","    for day in [1,2,3,4,5]:\n","        labels.append(f'{day} Days Predict')\n","    for day in [1,2,3,4]:\n","        predict = models[day].predict(test_x_last)\n","        predict = np.reshape(predict, (predict.size, ))\n","        predict = scaler.inverse_transform([[i] for i in predict])\n","        area_data2 = np.append(area_data2, predict)\n","    \n","    area_data2 = np.around(area_data2.flatten(), 1).tolist()\n","    labels.pop(0)\n","    area_data1.pop(0)\n","    # df = pd.read_csv('Stock_Profile.csv', index_col=0)\n","    # df = df[['Name', 'News size']]\n","    # df = df.sort_values(by=['News size'], ascending=False)[:10]\n","    # bar_labels = df['Name'].values.tolist()\n","    # bar_data = df['News size'].values.tolist()\n","    # labels = str(labels).replace(\"'\", \"\").replace(\"[\", \"\").replace(\"]\", \"\")\n","    # area_data1 = str(area_data1).replace(\"[\", \"\").replace(\"]\", \"\")\n","    # area_data2 = str(area_data2).replace(\"[\", \"\").replace(\"]\", \"\")\n","    # bar_labels = str(bar_labels).replace(\"'\", \"\").replace(\"[\", \"\").replace(\"]\", \"\")\n","    # bar_data = str(bar_data).replace(\"[\", \"\").replace(\"]\", \"\")\n","    bar_labels = \"2021-02-01, 2021-02-02, 2021-02-03, 2021-02-04, 2021-02-05, 2021-02-06, 2021-02-07, 2021-02-08, 2021-02-09, 2021-02-10, 2021-02-11, 2021-02-12, 2021-02-13, 2021-02-14, 2021-02-15, 2021-02-16, 2021-02-17, 2021-02-18, 2021-02-19, 2021-02-20\"\n","    bar_data = \"165, 144, 141, 125, 118, 113, 112, 111, 107, 101, 99\"\n","    return labels, area_data1, area_data2, bar_labels, bar_data\n","\n","get_twii_data()"]}],"metadata":{"colab":{"authorship_tag":"ABX9TyPMZixFkpwrU1A5RulqEae1","collapsed_sections":[],"name":"Model_Application.ipynb","provenance":[]},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"}},"nbformat":4,"nbformat_minor":0}
